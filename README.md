# Music genre classification using Machine Learning 
In the current melody maniac scenarios, with emerging automation of different music providing applications such as Spotify (on top), Apple music, YouTube Premium music, etc., interacting with the user and fulfilling the needs of the users before they demand for it is inescapable now. For reference, different user interactive features that are available in Spotify are, the ability for users to select their own music tastes, and according to the usage and listening experience of the user it creates different playlists for the user that are exclusively available for them. It also categorizes the different genres of songs in different specific playlists. Additionally, by analyzing the activity of the user it also creates a time capsule, repeat rewind playlists, and also with the help of it, suggests different playlists with same genre to the user. 

On the other hand, if we take the example of Apple music, it provides all the features mentioned above, additionally it also comprises of some other features such as it enables user to search a song by its lyrics, or the user can also voice search the lyrics using the Voice Assistant of Apple, Siri. It also creates the latest releases, collaborations and playlists of the favorite singer of the user, all in one cluster.

Along with these two applications we have a number of other such applications available in the market. As the number of applications increase the variety of the features increase. These above features help the application to be more interactive to the users. One of such features is Music Genre Classification and this feature comes under the Recommendation System.

First and foremost, the music files that will be fed into the neural network are sourced from GTZAN, which is a dataset available in TensorFlow. It contains 100, 30-second-long tracks that are each of 10 different genres which are 22050Mhz Mono 16-bit files in .wav format. This database is part of the Marsyas (Music Analysis, Retrieval and Synthesis for Audio Signals) framework designed by George Tzanetakis.

Furthermore, we will be using the following machine learning techniques to achieve our objectives
	• CNN (Convolutional Neural Networks)
	Convolutional Neural Networks are a type of neural network which work best when working with audio or visual datasets, hence the most suitable neural 		network for our needs. We will be using the following layers to build our CNN
       	◦ Convolutional layer: This is the base layer of a convolutional neural network where most of the computation occurs. It consists of input data, filter 	and a feature map. The input data corresponds to different dimensions of a file also known as weights.
        ◦ Pooling layer: This is the second layer of a CNN is the pooling layer which applies dimensionality to the dataset by using an aggregate function. The 	two main types of pooling are:
            ▪ Max pooling: Selects the highest value across the dataset to send to the output array.
            ▪ Average pooling: Calculates the average of the dataset and sends it to the output array.
        ◦ Fully-connected layer: This is the final layer of a CNN which is connected to all the nodes of the previous layer thus acting as the bridge between the 	  different layers.
• SVM (Support Vector Machines): This is a type of machine learning algorithm that similar to linear regression, helps us in classifying datasets. SVMs 	are the best available algorithms for performing classification tasks which will help us getting the most accurate results.
• kNN (K-Nearest Neighbors): This is another regression algorithm that works on the basis of proximity of different datasets to each other, as similar 		datasets are often in close proximity to each other.
